Facebook Inc. has been criticized for allowing its platform to amplify anti-vaccine views, fueling a public health crisis. Now the company is taking steps to reduce the visibility of the information in search and the news feed. Facebook won’t allow anti-vaccine views to pop up in search or recommendations on the social network or Instagram, and will reject ads that contain misinformation about vaccines, the company said Thursday. Facebook is also removing the ads targeting a category for “vaccine controversies.” Last month, U.S. Representative Adam Schiff, a Democrat from California, sent a letter to Facebook and Google, asking them to address the problem because their inaction may have contributed to recent outbreaks of measles in the country. Google’s YouTube turned off the ability for anti-vaccination videos to make money from their ads. Pinterest banned the content altogether. Facebook, where executives for years have said they are uncomfortable determining what is true and false, is starting to listen to critics who have explained the ways its algorithms amplify extreme content. The system helps spread niche and controversial views. Anti-vaccination groups have thrived in Facebook groups where the platform’s recommendation engine can promote other fringe ideas to follow. Facebook said it is also thinking about promoting information from expert organizations about vaccines at the top of results for related searches — a step beyond its usual tactic of de-ranking misinformation. Generally, Facebook has relied on a third-party fact-checking network that isn’t able to address all the false content on the site. The company is prioritizing taking action against content that the World Health Organization and the U.S. Centers for Disease Control and Prevention has publicly identified as false.