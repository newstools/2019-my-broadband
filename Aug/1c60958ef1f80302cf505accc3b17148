Two years ago, 10 sailors died when the U.S. Navy’s guided missile destroyer USS John S. McCain collided with a chemical tanker off Singapore. An investigation has determined that insufficient training and inadequate operating procedures were to blame, and both factors were related to a new touch-screen-based helm control system. The Navy has decided to revert its destroyers back to entirely physical throttles and helm controls. It’s worth exploring the Navy’s rationale for installing touch-screens (“Just because you can doesn’t mean you should,” says Rear Admiral Bill Galinis), as well as its rationale for getting rid of them: Galinis said that bridge design is something that shipbuilders have a lot of say in, as it’s not covered by any particular specification that the Navy requires builders to follow. As a result of innovation and a desire to incorporate new technology, “we got away from the physical throttles, and that was probably the number-one feedback from the fleet – they said, just give us the throttles that we can use.” There are lessons here — including a prescient one from 50 years ago — for other, more mundane transport-control interfaces as well. Large, interactive touch-screens are becoming increasingly prevalent in passenger cars; in the case of Tesla, they’re the only control interface. They’re lovely to look at, but as the Navy’s experience suggests, they might be more confusing than physical controls. That confusion isn’t academic, either: Distracted driving is an increasingly dangerous problem. According to the National Highway Traffic Safety Administration, 10% of all fatal crashes from 2012 to 2017 involved distracted drivers. Mobile phones are a major cause of distraction, as we’d expect, but they’re an even bigger problem for younger drivers. Almost 50 years ago, robotics professor Masahiro Mori wrote an extraordinary essay, “The Uncanny Valley,” on people’s reactions to robots as they became more and more humanlike. As Mori said, our affinity for robots rises as they more closely resemble humans. That affinity plunges, becoming negative and finally rising again once a robot reaches the (possibly unattainable) full likeness of a human being. Something similar is at work in our current touch-screen-filled vehicles. To an extent, adding more screen real estate give us more information, and with it more safety — until it begins to provide an overwhelming amount of information and an overly complex set of choices for visual navigation. And moving from one information-rich interface to another is increasingly difficult, as another Navy rear admiral said in reviewing the John S. McCain collision: When you look at a screen, where do you find heading? Is it in the same place, or do you have to hunt every time you go to a different screen? So the more commonality we can drive into these kind of human-machine interfaces, the better it is for the operator to quickly pick up what the situational awareness is, whatever aspect he’s looking at, whether it’s helm control, radar pictures, whatever. So we’re trying to drive that. There are two ways our in-car screens could evolve. The first is that, for safety’s sake, they’ll move back down the curve, so to speak, and be less ambiguous and more full of knobs and dials and physical throttles. That’s the Navy’s new approach. The second, though, is that we won’t go back, at least in passenger applications, to a more tactile interface of specific controls. We’re probably going to get more screens, with more information. Maybe the only way out of this valley is to shift the interface completely to voice or, in the very long run, to obviate the issue by having cars drive themselves. That could be how we navigate this uncanny valley of vehicle interfaces — the removal of any need to control the vehicle at all, and the chance to fill our cars’ screens with pure entertainment.